{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "510f8a8e",
   "metadata": {},
   "source": [
    "# Fine-Tuning SBERT for Clarifying Ambiguous Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373fc034",
   "metadata": {},
   "source": [
    "Fine-Tuning Sentence-BERT on Ambiguous Queries and Clarifying Questions for Conversational Search\n",
    "\n",
    "In this notebook, we fine-tune a pre-trained Sentence-BERT (SBERT) model to handle ambiguous user queries and their corresponding clarifying questions. This task aims to improve the model's ability to identify and generate appropriate clarifications, which is essential for enhancing conversational search systems.\n",
    "\n",
    "The dataset used in this experiment consists of pairs of user queries and their corresponding clarifying questions. We train the model to map user queries to clarifications, allowing it to understand ambiguous queries and respond with suitable follow-up questions.\n",
    "\n",
    "The main steps include:\n",
    "1. Preprocessing the data from a JSON format.\n",
    "2. Training the model on the query-clarification pairs using the `MultipleNegativesRankingLoss` function.\n",
    "3. Evaluating the model's performance using similarity scoring.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062835cf",
   "metadata": {},
   "source": [
    "# 1.Install Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a30606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\sayali\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\sayali\\anaconda3\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\sayali\\anaconda3\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: requests in c:\\users\\sayali\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from sentence-transformers) (9.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.9.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: filelock in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (2024.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2.11.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2.8.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas sentence-transformers datasets requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13120d69",
   "metadata": {},
   "source": [
    "# 2. Load and Explore the JSON Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17c836c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: <class 'dict'>\n",
      "Total Number of Keys: 198\n",
      "First Few Keys: ['obama family tree', 'cheap internet', 'ritz carlton lake las vegas', 'fickle creek farm', 'madam cj walker']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Download JSON from GitHub\n",
    "url = \"https://raw.githubusercontent.com/Sayalinale/Conversational-AI/refs/heads/main/qulac_for_wiki.json\"\n",
    "response = requests.get(url)\n",
    "data = json.loads(response.text)\n",
    "\n",
    "# View the structure\n",
    "print(\"Data Type:\", type(data))\n",
    "print(\"Total Number of Keys:\", len(data))\n",
    "print(\"First Few Keys:\", list(data.keys())[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1bc31d",
   "metadata": {},
   "source": [
    "# 3. Inspect Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4bc7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Key: obama family tree\n",
      "Associated Data: ['find the time magazine photo essay \\\\\"barack obama\\\\\\'s family tree\\\\\".', \"where did barack obama\\\\'s parents and grandparents come from?\", \"find biographical information on barack obama\\\\'s mother.\"]\n"
     ]
    }
   ],
   "source": [
    "# Pick one sample to understand its structure\n",
    "sample_key = list(data.keys())[0]\n",
    "print(f\"Sample Key: {sample_key}\")\n",
    "print(\"Associated Data:\", data[sample_key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4151ba4",
   "metadata": {},
   "source": [
    "# 4. Extract Queries and Clarifying Questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3702a203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 198 Queries and 198 Clarifications\n"
     ]
    }
   ],
   "source": [
    "queries = []\n",
    "clarifications = []\n",
    "\n",
    "for key, item in data.items():\n",
    "    if len(item) > 0:\n",
    "        queries.append(item[0])  # First element is the user query\n",
    "    else:\n",
    "        queries.append(None)\n",
    "\n",
    "    if len(item) > 1:\n",
    "        clarifications.append(item[1])  # Second element is the clarification\n",
    "    else:\n",
    "        clarifications.append(None)\n",
    "\n",
    "print(f\"Extracted {len(queries)} Queries and {len(clarifications)} Clarifications\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf95f83",
   "metadata": {},
   "source": [
    "# 5.Create and Save Dataset for Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ccdfd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as 'sbert_training_data.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Query</th>\n",
       "      <th>Clarifying Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>find the time magazine photo essay \\\"barack ob...</td>\n",
       "      <td>where did barack obama\\'s parents and grandpar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are some low-cost broadband internet prov...</td>\n",
       "      <td>do any internet providers still sell dial-up?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>find information about the ritz carlton resort...</td>\n",
       "      <td>find a site where i can determine room price a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>find general information about fickle creek fa...</td>\n",
       "      <td>where is fickle creek farm, and how can i go t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>find historical information about madam c. j. ...</td>\n",
       "      <td>find information about the business that c. j....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          User Query  \\\n",
       "0  find the time magazine photo essay \\\"barack ob...   \n",
       "1  what are some low-cost broadband internet prov...   \n",
       "2  find information about the ritz carlton resort...   \n",
       "3  find general information about fickle creek fa...   \n",
       "4  find historical information about madam c. j. ...   \n",
       "\n",
       "                                 Clarifying Question  \n",
       "0  where did barack obama\\'s parents and grandpar...  \n",
       "1      do any internet providers still sell dial-up?  \n",
       "2  find a site where i can determine room price a...  \n",
       "3  where is fickle creek farm, and how can i go t...  \n",
       "4  find information about the business that c. j....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'User Query': queries,\n",
    "    'Clarifying Question': clarifications\n",
    "})\n",
    "\n",
    "# Remove incomplete data\n",
    "df = df.dropna()\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('sbert_training_data.csv', index=False)\n",
    "print(\"Dataset saved as 'sbert_training_data.csv'.\")\n",
    "\n",
    "# Show sample\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f86790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset also saved to C:\\Users\\sayali\\Downloads\\sbert_training_data.csv.\n"
     ]
    }
   ],
   "source": [
    "# Save to specific local directory (Windows path)\n",
    "df.to_csv(r'C:\\Users\\sayali\\Downloads\\sbert_training_data.csv', index=False)\n",
    "print(\"Dataset also saved to C:\\\\Users\\\\sayali\\\\Downloads\\\\sbert_training_data.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51076ebf",
   "metadata": {},
   "source": [
    "# 6.Prepare Data for SBERT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b552d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 196 training examples.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "train_examples = [\n",
    "    InputExample(texts=[row['User Query'], row['Clarifying Question']])\n",
    "    for index, row in df.iterrows()\n",
    "]\n",
    "print(f\"Prepared {len(train_examples)} training examples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2c2cbc",
   "metadata": {},
   "source": [
    "# 7. Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5aa61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494d7e16",
   "metadata": {},
   "source": [
    "# 8. Load Pre-trained SBERT Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d681d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d8948",
   "metadata": {},
   "source": [
    "# 9.Define Loss Function for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "778daf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6321b8",
   "metadata": {},
   "source": [
    "# 10.Fine-Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4018373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\sayali\\anaconda3\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: xxhash in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e97e976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\sayali\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from transformers[torch]) (0.30.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from transformers[torch]) (2022.7.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from transformers[torch]) (2.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.13.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sayali\\appdata\\roaming\\python\\python39\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (2.11.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2022.9.14)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sayali\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade \"transformers[torch]\" accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddbc60e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 01:27, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=4,            # adjust this number\n",
    "    warmup_steps=100,    # Small warmup for stable learning\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1619108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.8960805535316467\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('fine_tuned_sbert')\n",
    "\n",
    "query = \"obama family tree\"\n",
    "clarification = \"What aspect of the Obama family tree are you asking about?\"\n",
    "\n",
    "# Encode both\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "clarification_embedding = model.encode(clarification, convert_to_tensor=True)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity = util.pytorch_cos_sim(query_embedding, clarification_embedding)\n",
    "print(\"Similarity Score:\", similarity.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e5fe0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.7534855604171753\n"
     ]
    }
   ],
   "source": [
    "test_query = \"Tell me about the Obama family history\"\n",
    "clarification = \"What aspect of the Obama family tree are you asking about?\"\n",
    "\n",
    "test_embedding = model.encode(test_query, convert_to_tensor=True)\n",
    "clarification_embedding = model.encode(clarification, convert_to_tensor=True)\n",
    "\n",
    "similarity = util.pytorch_cos_sim(test_embedding, clarification_embedding)\n",
    "print(\"Similarity Score:\", similarity.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7c7628",
   "metadata": {},
   "source": [
    "This notebook demonstrated the fine-tuning of a Sentence-BERT model on a dataset consisting of ambiguous user queries and clarifying questions. By utilizing the `MultipleNegativesRankingLoss` function, we trained the model to understand semantic similarities between the queries and clarifications.\n",
    "\n",
    "After training, we evaluated the model's ability to generate clarifications for new ambiguous queries, achieving a high similarity score. The fine-tuned model shows promise in improving conversational search systems, where handling user query ambiguity is crucial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a0b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
